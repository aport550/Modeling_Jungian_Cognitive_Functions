{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import sklearn\n",
    "import warnings\n",
    "from collections import Counter\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv('mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MBTI Type')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = Counter(df)\n",
    "X = pd.DataFrame.from_dict(count, orient='index')\n",
    "sb.set()\n",
    "types_count = df.iloc[:,0].value_counts()\n",
    "types_count.sort_values(ascending=True).plot('barh')\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"MBTI Type\")\n",
    "#ax = sb.distplot(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ne\"] = [1 if x[-1] == 'P' and x[1] == 'N' else 0 for x in df.iloc[:,0]]\n",
    "df[\"Ni\"] = [1 if x[-1] == 'J' and x[1] == 'N' else 0 for x in df.iloc[:,0]]\n",
    "df[\"Se\"] = [1 if x[-1] == 'P' and x[1] == 'S' else 0 for x in df.iloc[:,0]]\n",
    "df[\"Si\"] = [1 if x[-1] == 'J' and x[1] == 'S' else 0 for x in df.iloc[:,0]]\n",
    "df[\"Fi\"] = [1 if x[-1] == 'P' and x[2] == 'F' else 0 for x in df.iloc[:,0]]\n",
    "df[\"Fe\"] = [1 if x[-1] == 'J' and x[2] == 'F' else 0 for x in df.iloc[:,0]]\n",
    "df[\"Ti\"] = [1 if x[-1] == 'P' and x[2] == 'T' else 0 for x in df.iloc[:,0]]\n",
    "df[\"Te\"] = [1 if x[-1] == 'J' and x[2] == 'T' else 0 for x in df.iloc[:,0]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_use = np.array(df.columns[2:])\n",
    "counts = df.iloc[:,2:].apply(np.sum,axis=0)\n",
    "plt.bar(columns_to_use,counts)\n",
    "plt.xlabel(\"Primary Perceiving-Judging Functions\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Cognitive Functions are determined by the last 3 letters of MBTI Type, so isolate the last three letters\n",
    "\n",
    "df[\"NFP\"] = [1 if x == 'INFP' or x =='ENFP' else 0 for x in df.iloc[:,0]]\n",
    "df[\"NFJ\"] = [1 if x == 'INFJ' or x == 'ENFJ' else 0 for x in df.iloc[:,0]]\n",
    "df[\"NTP\"] = [1 if x == 'ENTP' or x =='INTP' else 0 for x in df.iloc[:,0]]\n",
    "df[\"NTJ\"] = [1 if x == 'ENTJ' or x == 'INTJ' else 0 for x in df.iloc[:,0]]\n",
    "df[\"STJ\"] = [1 if x == 'ESTJ' or x == 'ISTJ' else 0 for x in df.iloc[:,0]]\n",
    "df[\"STP\"] = [1 if x == 'ESTP' or x == 'ISTP' else 0 for x in df.iloc[:,0]]\n",
    "df[\"SFP\"] = [1 if x == 'ESFP' or x == 'ISFP' else 0 for x in df.iloc[:,0]]\n",
    "df[\"SFJ\"] = [1 if x == 'ESFJ' or x == 'ISFJ' else 0 for x in df.iloc[:,0]]\n",
    "df[\"E\"] = [1 if x[0] == 'E' else 0 for x in df.iloc[:,0]]\n",
    "\n",
    "\n",
    "# Resample the data Function\n",
    "def resample_df(df,samples):\n",
    "    downsampled = resample(df[df[\"NFP\"] == 1], replace=False,n_samples=samples,random_state=10) # reproducible results\n",
    "    downsampled2 = resample(df[df[\"NFJ\"] == 1], replace=False,n_samples=samples,random_state=10) # reproducible results\n",
    "    downsampled3 = resample(df[df[\"NTP\"] == 1], replace=False,n_samples=samples,random_state=10) # reproducible results\n",
    "    downsampled4 = resample(df[df[\"NTJ\"] == 1], replace=False,n_samples=samples,random_state=10) # reproducible results\n",
    "    downsampled5 = resample(df[df[\"SFP\"] == 1], replace=False,n_samples=samples,random_state=10) # reproducible results\n",
    "    downsampled6 = resample(df[df[\"SFJ\"] == 1], replace=False,n_samples=samples,random_state=10) # reproducible results\n",
    "    downsampled7 = resample(df[df[\"STP\"] == 1], replace=False,n_samples=samples,random_state=10) # reproducible results\n",
    "    downsampled8 = resample(df[df[\"STJ\"] == 1], replace=False,n_samples=samples,random_state=10) # reproducible results\n",
    "    downsampled_df = pd.concat([downsampled,downsampled2,downsampled3,downsampled4,downsampled5,downsampled6,downsampled7,downsampled8])\n",
    "    return downsampled_df\n",
    "resample_df(df,208)\n",
    "\n",
    "#Resample the data\n",
    "\n",
    "downsampled_df = resample_df(df,208)\n",
    "downsampled_df.iloc[:,0].value_counts()\n",
    "#print(len(downsampled_df))\n",
    "downsampled_df = downsampled_df.drop_duplicates(subset='posts', keep='first', inplace=False)\n",
    "#print(len(downsampled_df))\n",
    "\n",
    "#Graph the new distribution\n",
    "\n",
    "columns_to_use = np.array(downsampled_df.columns[2:10])\n",
    "counts = downsampled_df.iloc[:,2:10].apply(np.sum,axis=0)\n",
    "plt.bar(columns_to_use,counts)\n",
    "plt.xlabel(\"Primary Perceiving-Judging Functions\")\n",
    "plt.ylabel(\"Count\")\n",
    "dfd = downsampled_df\n",
    "dfd = dfd.reset_index(drop=True)\n",
    "#dfd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training set: 1408\n",
      "Size of Test set: 256\n",
      "\n",
      "Graph the testing set distribution to ensure cognitive function balance is maintained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(20)\n",
    "split = np.random.rand(dfd.shape[0])\n",
    "train_df = resample_df(dfd,176)\n",
    "test_df = pd.concat([dfd,train_df]).drop_duplicates(keep=False)\n",
    "\n",
    "print(f\"Size of Training set: {len(train_df)}\")\n",
    "print(f\"Size of Test set: {len(test_df)}\")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(\"\\nGraph the testing set distribution to ensure cognitive function balance is maintained\")\n",
    "columns_to_use = np.array(test_df.columns[2:10])\n",
    "counts = test_df.iloc[:,2:10].apply(np.sum,axis=0)\n",
    "plt.bar(columns_to_use,counts)\n",
    "plt.xlabel(\"Primary Perceiving-Judging Functions\")\n",
    "plt.ylabel(\"Count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter \n",
    "from string import punctuation\n",
    "\n",
    "#Clean the users posts and look for instances of certain punctuation\n",
    "\n",
    "def clean_posts(df,index):\n",
    "    \n",
    "    # For every user, split their posts into a list of posts\n",
    "    posts_list = df['posts'][index].split('|||')\n",
    "    count = 0\n",
    "    \n",
    "    # We will count the ratio of how many times each user used punctuations of different sorts\n",
    "    links = []\n",
    "    posts = []\n",
    "    Qmarks = []\n",
    "    commas = []\n",
    "    exclamations = []\n",
    "    length = len(posts_list)\n",
    "    \n",
    "    #Iterate through each post in the users posts\n",
    "    for count,post in enumerate(posts_list):\n",
    "        \n",
    "        # Use RE to find all the instances of links in each post\n",
    "        link = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', post) \n",
    "        # If the user has links append the link to the users \"link list\"\n",
    "        if(link!=[]):\n",
    "            links.append(link)\n",
    "                        \n",
    "        if(len(post) > 0):\n",
    "            commas.append(post.count(',') / len(post))\n",
    "            Qmarks.append(post.count('?') / len(post))\n",
    "            exclamations.append(post.count('!') / len(post))\n",
    "        else:\n",
    "            #If post list is empty dont count it\n",
    "            count -= 1\n",
    "            \n",
    "        posts.append(post)\n",
    "        #count+=1\n",
    "    #print(len(links),len(posts))\n",
    "    return [links, posts, np.mean(Qmarks), np.mean(commas),np.mean(exclamations)]\n",
    "#clean_posts(0)[1]\n",
    "# dfd['links'] = [clean_posts(dfd,count)[0] for count in range(len(dfd))]\n",
    "# dfd['post_list'] = [clean_posts(dfd,count)[1] for count in range(len(dfd))]\n",
    "def clean_df(df):\n",
    "    df['links'] = [clean_posts(df,count)[0] for count in range(len(df))]\n",
    "    df['post_list'] = [clean_posts(df,count)[1] for count in range(len(df))]\n",
    "    df['Qmarks'] = [clean_posts(df,count)[2] for count in range(len(df))]\n",
    "    df['commas'] = [clean_posts(df,count)[3] for count in range(len(df))]\n",
    "    df['exclamations'] = [clean_posts(df,count)[4] for count in range(len(df))]\n",
    "    #df['punctuations'] = [clean_posts(df,count)[5] for count in range(len(df))]\n",
    "train_df['links'] = [clean_posts(train_df,count)[0] for count in range(len(train_df))]\n",
    "train_df['post_list'] = [clean_posts(train_df,count)[1] for count in range(len(train_df))]\n",
    "train_df['Qmarks'] = [clean_posts(train_df,count)[2] for count in range(len(train_df))]\n",
    "train_df['commas'] = [clean_posts(train_df,count)[3] for count in range(len(train_df))]\n",
    "train_df['exclamations'] = [clean_posts(train_df,count)[4] for count in range(len(train_df))]\n",
    "\n",
    "\n",
    "test_df['links'] = [clean_posts(test_df,count)[0] for count in range(len(test_df))]\n",
    "test_df['post_list'] = [clean_posts(test_df,count)[1] for count in range(len(test_df))]\n",
    "test_df['Qmarks'] = [clean_posts(test_df,count)[2] for count in range(len(test_df))]\n",
    "test_df['commas'] = [clean_posts(test_df,count)[3] for count in range(len(test_df))]\n",
    "test_df['exclamations'] = [clean_posts(test_df,count)[4] for count in range(len(test_df))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train_df['punctuations'] = [clean_posts(train_df,count)[5] for count in range(len(train_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_irrelevant(df):\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns=[\"posts\",\"type\"])\n",
    "    df = df.drop(columns=['SFP','SFJ','STJ','STP','NFP','NFJ','NTP','NTJ'])\n",
    "    return df\n",
    "train_df = drop_irrelevant(train_df)\n",
    "test_df = drop_irrelevant(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/allanporter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk.tokenize\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import string\n",
    "def post_info(df,index):\n",
    "    words = []\n",
    "#     sent_lengths = []\n",
    "#     sents_per_post = []\n",
    "#     words_per_sent = []\n",
    "#     word_lengths = []\n",
    "#     words_per_post = []\n",
    "#     len_per_post = []\n",
    "#     total_len = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    for post in df['post_list'][index]:\n",
    "#         total_len += len(post)\n",
    "#         len_per_post.append(len(post))\n",
    "        #returns a list of sentences in the post\n",
    "        sent = sent_tokenize(post)\n",
    "        #get the amount of sentences in the post\n",
    "#         sents_per_post.append(len(sent))\n",
    "        #get the amount of words in a sentece\n",
    "        for s in sent:\n",
    "#             sent_lengths.append(len(s))\n",
    "            words_in_sentence = s.split(' ')\n",
    "#             words_per_sent.append(len(words_in_sentence))\n",
    "        word = post.split(' ')\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in word]\n",
    "        for w in stripped:\n",
    "            if(w != ''):\n",
    "#                 word_lengths.append(len(w))\n",
    "                words.append(w.lower())\n",
    "#         words_per_post.append(len(stripped))\n",
    "        total_words += len(stripped)\n",
    "\n",
    "#     avg_sent_length = np.mean(sent_lengths)\n",
    "#     avg_sents_per_post = np.mean(sents_per_post)\n",
    "#     avg_word_length = np.mean(word_lengths)\n",
    "#     avg_words_per_sent = np.mean(words_per_sent)\n",
    "#     avg_words_per_post = np.mean(words_per_post)\n",
    "#     avg_len_per_post = np.mean(len_per_post)\n",
    "    \n",
    "    word_counts = {}\n",
    "    for w in words:\n",
    "        #word = w.strip(unwanted_chars)\n",
    "        if w not in word_counts:\n",
    "            word_counts[w] = 0 \n",
    "        word_counts[w]+=1\n",
    "    wc = sorted(word_counts.items(), key=lambda w:w[1], reverse=True)\n",
    "    wc = [list(e) for e in wc]\n",
    "#     for w in wc:\n",
    "#         if(w[1] == 1):\n",
    "#             #print(w)\n",
    "#             wc.remove(w)\n",
    "\n",
    "    return [wc,total_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Words to Use as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_person = [\"i\", \"me\", \"ill\", \"ive\", \"id\", \"im\", \"me\", \"my\", \"myself\"]\n",
    "second_person = [\"you\",\"youve\",\"youd\",\"youll\",\"youre\",\"your\",\"yourself\"]\n",
    "pop_culture = ['lol','lmao','omg']\n",
    "cloud_words = ['like', 'um', 'thingy']\n",
    "slang = ['sup','bro','yo','dude','totally']\n",
    "shortened = ['brb','rn','fr','bmt','bff','nbd','b4','abt','2day','2moro','2nite','gn','lemme','kno','gtg','ttyl','stfu']\n",
    "ext = ['really','very']\n",
    "other_laugh = ['ha','haha','hahaha', 'hahahaha']\n",
    "third_laugh = ['aha', 'ahaha', 'ahahaha', 'ahahahaha']\n",
    "feeling = ['feelings','feel','felt','feeling','feels']\n",
    "thinking = ['thought','think','thoughts','thinking','thinks']\n",
    "love_words = ['love','loved','aww','aw','awww','awwww','lover','loving']\n",
    "fancy = ['indeed', 'lovely']\n",
    "short_gratitude = ['np','thx','thanx','thnx','prob']\n",
    "ok_vars = ['k','kk']\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words = list(stop_words)\n",
    "punctuationless_stop_words = [\"ive\",\"im\",\"would\",\"should\",\"is\",\"ill\",\"wouldnt\",\"shouldnt\",\"isnt\",\"didnt\",\"dont\",\"wont\",\"cant\",\"couldnt\"]\n",
    "for w in punctuationless_stop_words:\n",
    "    stop_words.append(w)\n",
    "\n",
    "total_list = first_person + second_person + pop_culture + cloud_words + slang + shortened + ext + feeling + thinking + love_words + short_gratitude + ok_vars \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_list\n",
    "def get_word_totals(words,temp):\n",
    "    #like_list = 0\n",
    "    like_list = []\n",
    "    for i, row in enumerate(temp.itertuples()):\n",
    "    #for t in range(len(temp)):\n",
    "        info = post_info(temp,i)\n",
    "        #print(info)\n",
    "        words_arr =  info[0]\n",
    "        word_count = info[1]\n",
    "        like_count = 0\n",
    "        #if words_arr.string.contains\n",
    "        for w in words_arr:\n",
    "            if(w[0] in words):\n",
    "                like_count = w[1]\n",
    "        like_entry = (like_count / word_count)\n",
    "        like_list.append(like_entry)\n",
    "    return like_list\n",
    "def add_word_columns(temp,words):\n",
    "    for i in range(len(words)):\n",
    "    #print(words[i])\n",
    "        word = words[i]\n",
    "        like_list = get_word_totals(word, temp)\n",
    "        #print(like_list[0])\n",
    "        temp[word] = like_list\n",
    "        #print(temp[word])\n",
    "        print(i)\n",
    "\n",
    "# add_word_columns(train_df,total_list)\n",
    "# add_word_columns(test_df,total_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def wordlist(words,temp):\n",
    "    #like_list = 0\n",
    "    like_list = []\n",
    "    for i, row in enumerate(temp.itertuples()):\n",
    "    #for t in range(len(temp)):\n",
    "        info = post_info(temp,i)\n",
    "        #print(info)\n",
    "        words_arr =  info[0]\n",
    "        word_count = info[1]\n",
    "        like_count = 0\n",
    "        #if words_arr.string.contains\n",
    "        for w in words_arr:\n",
    "            if(w[0] in words):\n",
    "                like_count += w[1]\n",
    "        like_entry = (like_count / word_count)\n",
    "        like_list.append(like_entry)\n",
    "    return like_list\n",
    "\n",
    "def add_word_columns(temp,words,column):\n",
    "    #for i in range(start,end):\n",
    "    #print(words[i])\n",
    "    #word = words[i]\n",
    "    like_list = wordlist(words, temp)\n",
    "    #print(like_list[0])\n",
    "    temp[column] = like_list\n",
    "    #print(temp[word])\n",
    "    #print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feats(df):\n",
    "    add_word_columns(df,first_person,'first person')\n",
    "    add_word_columns(df,second_person,'second person')\n",
    "    add_word_columns(df,pop_culture,'pop culture')\n",
    "#     add_word_columns(df,curse_words,'curse words')\n",
    "    add_word_columns(df,cloud_words,'cloud words')\n",
    "    add_word_columns(df,stop_words,'stop_words')\n",
    "    add_word_columns(df,slang,'slang')\n",
    "    add_word_columns(df,shortened,'shortened')\n",
    "    add_word_columns(df,ext,'ext')\n",
    "    add_word_columns(df,feeling,'feeling')\n",
    "    add_word_columns(df,thinking,'thinking')\n",
    "    add_word_columns(df,ok_vars,'ok_vars')\n",
    "    add_word_columns(df,short_gratitude,'short_gratitude')\n",
    "    add_word_columns(df,fancy,'fancy')\n",
    "    add_word_columns(df,love_words,'love_words')\n",
    "    add_word_columns(df,other_laugh,'other_laugh')\n",
    "    add_word_columns(df,third_laugh,'third_laugh')\n",
    "\n",
    "add_feats(train_df)\n",
    "add_feats(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ['I don't hate anything about myself, but one ...\n",
       "1       ['Just remember, if you believe things happen ...\n",
       "2       ['I can't really believe these news websites e...\n",
       "3       ['As an INFP, I will attempt to get into this ...\n",
       "4       ['I'm an INFP and I'm sick of looking at posts...\n",
       "5       ['I nod yes, but with a slight tilt of the hea...\n",
       "6       ['I have this too...though they're usually alm...\n",
       "7       ['ENFP 7w6, I think. There's a 9 in there some...\n",
       "8       ['I just can't with this guy. I liked him on a...\n",
       "9       ['I just decided yesterday in fact, to become ...\n",
       "10      ['My roommate is an INFP. How this happened, I...\n",
       "11      ['Wow!  That's very IDEALISTIC of you.  This c...\n",
       "12      ['my posture was bad bad bad. i didn't even re...\n",
       "13      [I attended a workshop on emotional intelligen...\n",
       "14      ['I'm inclined to say that you're is a Ti user...\n",
       "15      [as far as I live in this world, I've never be...\n",
       "16      ['This is a good idea. I'm watching In the Fle...\n",
       "17      ['I do love to stumble upon fascinating connec...\n",
       "18      ['I feel like I am in a slump. Day two of Camp...\n",
       "19      ['First Listen: 'Music For Shut-Ins' : NPR, So...\n",
       "20      ['Have a nice morning from Prague btw. Spring ...\n",
       "21      ['363114, Have you talked to your husband abou...\n",
       "22      ['I'm still a virgin, there are two reasons re...\n",
       "23      ['i have a love-hate thing with showers.  bath...\n",
       "24      ['I have often noticed that reality is not in ...\n",
       "25      ['Comments I got in school essays: Get to the ...\n",
       "26      ['That's an opinion, not a fact.  That being s...\n",
       "27      ['Maybe I'm little bit too much into 'Stranger...\n",
       "28      ['How the Buttonhole of the Month system works...\n",
       "29      ['3:24 pm - Saturday  I miss you  I miss you, ...\n",
       "                              ...                        \n",
       "1378    ['And I think that the only people who might b...\n",
       "1379    [Welcome....and enjoy the ride!!!, Only marry ...\n",
       "1380    ['I really empathised with the narrator's thou...\n",
       "1381    ['I just typed my ex-wife, who is an ESFP.  Un...\n",
       "1382    [I'm always for inflating my ego -  Energy Dri...\n",
       "1383    [My girlfriend tells me I can't take a hint, b...\n",
       "1384    [No, no I haven't. I don't know that I can obj...\n",
       "1385    ['My memory is bad, last thing I remember is I...\n",
       "1386    ['Stuff that I'm all pretty good at.... What a...\n",
       "1387    ['http://www.youtube.com/watch?v=EOgfZHxTgts, ...\n",
       "1388    ['It's about that time where I'm going to star...\n",
       "1389    [In matters of romance it comes down to the in...\n",
       "1390    ['Once I'm in one, I love it.  When I'm in a r...\n",
       "1391    ['Hello all,  For the longest time, I've alway...\n",
       "1392    ['How was it that you became friends?, Ask., I...\n",
       "1393    ['I am creative, usually with lots of ideas bu...\n",
       "1394    ['Now let's hold on a minute here.  The four m...\n",
       "1395    ['Im direct and straightforward to the point ...\n",
       "1396    ['What do you mean. i thought Myers Bridds was...\n",
       "1397    ['Had a dog growing up from when I was 8 until...\n",
       "1398    ['Like it was already mentioned, just try to g...\n",
       "1399    [Two close friends of mine are both strong ENT...\n",
       "1400    ['the term Finding an acceptable risk comes to...\n",
       "1401    ['http://www.youtube.com/watch?v=GDDaS4o-UR4, ...\n",
       "1402    ['Or when someone bails last minute (or even w...\n",
       "1403    ['i have the need to feel wanted, but not real...\n",
       "1404    ['Do you know where the username and avatar or...\n",
       "1405    ['I don't think anything about her is an ISTJ....\n",
       "1406    ['Stereotyping doesn't help you. Sorry I could...\n",
       "1407    ['INFP because both Si-Te and Fi-Ne are appare...\n",
       "Name: post_list, Length: 1408, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['post_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "ps = PorterStemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_posts = []\n",
    "for count,posts in enumerate(train_df.itertuples()):\n",
    "    post_list = train_df.iloc[count].post_list\n",
    "    new_post_list = []\n",
    "    for post in post_list:\n",
    "        post = post.replace(\"'\", \"\")\n",
    "        new_post_list.append(post)\n",
    "    new_posts.append(new_post_list)\n",
    "# for post in train_df['post_list'][0]:\n",
    "#     for word in word_tokenize(post):\n",
    "#         print(ps.stem(word))\n",
    "train_df['new_posts'] = new_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "dont\n",
      "hate\n",
      "anyth\n",
      "about\n",
      "myself\n",
      ",\n",
      "but\n",
      "one\n",
      "perplex\n",
      "thing\n",
      "is\n",
      "the\n",
      "seemingli\n",
      "unlimit\n",
      "capac\n",
      "to\n",
      "feel\n",
      "sad\n",
      "...\n",
      "sometim\n",
      "it\n",
      "just\n",
      "there\n",
      ",\n",
      "and\n",
      "the\n",
      "reason\n",
      ",\n",
      "solut\n",
      ",\n",
      "or\n",
      "ani\n",
      "salient\n",
      "detail\n",
      "seem\n",
      "...\n",
      "ha\n",
      "anyon\n",
      "found\n",
      "ani\n",
      "use\n",
      "method\n",
      "for\n",
      "deal\n",
      "with\n",
      "the\n",
      "oppos\n",
      "side\n",
      "of\n",
      "their\n",
      "infp\n",
      "person\n",
      "?\n",
      "I\n",
      "have\n",
      "found\n",
      "that\n",
      "the\n",
      "fi/n\n",
      "side\n",
      "of\n",
      "me\n",
      "desir\n",
      "someth\n",
      "(\n",
      "which\n",
      "I\n",
      "cant\n",
      "yet\n",
      "identifi\n",
      ")\n",
      "much\n",
      "...\n",
      "Hi\n",
      "all\n",
      ",\n",
      "ive\n",
      "been\n",
      "struggl\n",
      "for\n",
      "quit\n",
      "a\n",
      "few\n",
      "year\n",
      "with\n",
      "thi\n",
      "insati\n",
      "crave\n",
      "for\n",
      "some\n",
      "kind\n",
      "of\n",
      "realiz\n",
      ",\n",
      "answer\n",
      ",\n",
      "or\n",
      "transcend\n",
      "epiphani\n",
      "of\n",
      "some\n",
      "sort\n",
      "to\n",
      "a\n",
      "vagu\n",
      ",\n",
      "unend\n",
      "sens\n",
      "of\n",
      "...\n",
      "the\n",
      "unhealthi\n",
      "to\n",
      "healthi\n",
      "journey\n",
      "for\n",
      "me\n",
      "wa\n",
      "a\n",
      "few\n",
      "year\n",
      "of\n",
      "therapi\n",
      "while\n",
      "in\n",
      "colleg\n",
      ".\n",
      "then\n",
      "it\n",
      "wa\n",
      "just\n",
      "work\n",
      "(\n",
      "as\n",
      "a\n",
      "teacher\n",
      ")\n",
      "and\n",
      "get\n",
      "realli\n",
      "into\n",
      "it\n",
      "day\n",
      "in\n",
      "and\n",
      "day\n",
      "out\n",
      "even\n",
      "though\n",
      "it\n",
      "suck\n",
      "a\n",
      "lot\n",
      "...\n",
      "I\n",
      "have\n",
      "been\n",
      "encourag\n",
      "by\n",
      "the\n",
      "recent\n",
      "news\n",
      "that\n",
      "sweden\n",
      "is\n",
      "switch\n",
      "to\n",
      "a\n",
      "6\n",
      "hour\n",
      "workday\n",
      ".\n",
      "It\n",
      "show\n",
      "that\n",
      "slowli\n",
      "some\n",
      "pocket\n",
      "of\n",
      "our\n",
      "mass\n",
      "consciou\n",
      "are\n",
      "awar\n",
      "that\n",
      "it\n",
      "doesnt\n",
      "need\n",
      "to\n",
      "be\n",
      "thi\n",
      "way\n",
      "and\n",
      "we\n",
      "...\n",
      "thank\n",
      "you\n",
      "both\n",
      "for\n",
      "your\n",
      "respons\n",
      ".\n",
      ":\n",
      "-\n",
      ")\n",
      "two\n",
      "thing\n",
      "realli\n",
      "rang\n",
      "true\n",
      ":\n",
      "one\n",
      ",\n",
      "that\n",
      "I\n",
      "should\n",
      "disconnect\n",
      "myself\n",
      "from\n",
      "time\n",
      "measur\n",
      "on\n",
      "my\n",
      "day\n",
      "off\n",
      ",\n",
      "and\n",
      "cut\n",
      "out\n",
      "the\n",
      "activ\n",
      "that\n",
      "havent\n",
      "been\n",
      "work\n",
      "...\n",
      "anyon\n",
      "got\n",
      "ani\n",
      "advic\n",
      "for\n",
      "me\n",
      "?\n",
      "Im\n",
      "current\n",
      "work\n",
      "a\n",
      "job\n",
      "that\n",
      "I\n",
      "am\n",
      "sure\n",
      "mani\n",
      "would\n",
      "want\n",
      "--\n",
      "I\n",
      "am\n",
      "teach\n",
      "english\n",
      "in\n",
      "japan\n",
      ".\n",
      "howev\n",
      ",\n",
      "I\n",
      "am\n",
      "at\n",
      "a\n",
      "big\n",
      "corpor\n",
      ",\n",
      "and\n",
      "while\n",
      "certainli\n",
      "the\n",
      "environ\n",
      "...\n",
      "today\n",
      "at\n",
      "work\n",
      "I\n",
      "wa\n",
      "tell\n",
      "my\n",
      "cowork\n",
      "about\n",
      "a\n",
      "show\n",
      "I\n",
      "watch\n",
      "on\n",
      "netflix\n",
      ".\n",
      "I\n",
      "said\n",
      "it\n",
      "wa\n",
      "a\n",
      "netflix\n",
      "origin\n",
      "seri\n",
      "becaus\n",
      "that\n",
      "what\n",
      "it\n",
      "said\n",
      "in\n",
      "the\n",
      "begin\n",
      "of\n",
      "everi\n",
      "episod\n",
      ".\n",
      "she\n",
      "said\n",
      "quit\n",
      "...\n",
      "I\n",
      "think\n",
      "like\n",
      "ani\n",
      "averag\n",
      "Fi\n",
      "user\n",
      ",\n",
      "I\n",
      "am\n",
      "constantli\n",
      "weigh\n",
      "the\n",
      "good\n",
      "and\n",
      "evil\n",
      "of\n",
      "my\n",
      "emot\n",
      ",\n",
      "thought\n",
      ",\n",
      "impuls\n",
      ",\n",
      "sensat\n",
      ",\n",
      "etc\n",
      ".\n",
      "I\n",
      "have\n",
      "a\n",
      "lot\n",
      "of\n",
      "inner\n",
      "anger\n",
      "and\n",
      "mess\n",
      "up\n",
      "emot\n",
      "center\n",
      "...\n",
      "I\n",
      "constantli\n",
      "feel\n",
      "guilti\n",
      "and\n",
      "feel\n",
      "veri\n",
      "close\n",
      "to\n",
      "and\n",
      "awar\n",
      "of\n",
      "mani\n",
      "feel\n",
      ",\n",
      "thought\n",
      ",\n",
      "percept\n",
      ",\n",
      "and\n",
      "behavior\n",
      "that\n",
      "I\n",
      "consid\n",
      "evil\n",
      ",\n",
      "bad\n",
      ",\n",
      "abject\n",
      ",\n",
      "etc\n",
      ".\n",
      "the\n",
      "averag\n",
      "person\n",
      "who\n",
      "know\n",
      "me\n",
      "will\n",
      "...\n",
      "make\n",
      "sens\n",
      ".\n",
      "My\n",
      "trityp\n",
      "usual\n",
      "seem\n",
      "to\n",
      "be\n",
      "461\n",
      ".\n",
      "I\n",
      "frequent\n",
      "worri\n",
      ",\n",
      "like\n",
      "how\n",
      "quang\n",
      "describ\n",
      ",\n",
      "about\n",
      "becom\n",
      "a\n",
      "drug\n",
      "addict\n",
      ",\n",
      "about\n",
      "lose\n",
      "my\n",
      "mind\n",
      ",\n",
      "etc\n",
      ".\n",
      "howev\n",
      ",\n",
      "I\n",
      "had\n",
      "earli\n",
      "traumat\n",
      "experi\n",
      "...\n",
      "which\n",
      "enneagram\n",
      "type\n",
      "is\n",
      "the\n",
      "most\n",
      "like\n",
      "to\n",
      "feel\n",
      "an\n",
      "acut\n",
      "anxieti\n",
      "about\n",
      "be\n",
      "bad\n",
      "or\n",
      "evil\n",
      "?\n",
      "To\n",
      "wrestl\n",
      "with\n",
      "an\n",
      "obsess\n",
      "fear\n",
      "at\n",
      "the\n",
      "prospect\n",
      "of\n",
      ",\n",
      "in\n",
      "the\n",
      "futur\n",
      ",\n",
      "commit\n",
      "evil\n",
      "action\n",
      ",\n",
      "the\n",
      "...\n",
      "thank\n",
      "you\n",
      "all\n",
      ".\n",
      "veri\n",
      "good\n",
      "advic\n",
      "here\n",
      ".\n",
      "and\n",
      "even\n",
      "in\n",
      "the\n",
      "simplest\n",
      "sens\n",
      "it\n",
      "feel\n",
      "better\n",
      "to\n",
      "know\n",
      "that\n",
      "there\n",
      "are\n",
      "other\n",
      "who\n",
      "understand\n",
      "thi\n",
      "particular\n",
      "experi\n",
      "of\n",
      "life\n",
      ".\n",
      "what\n",
      "get\n",
      "me\n",
      "late\n",
      "is\n",
      "the\n",
      "...\n",
      "how\n",
      "do\n",
      "you\n",
      "deal\n",
      "with\n",
      "the\n",
      "hypervigil\n",
      "and\n",
      "irrit\n",
      "?\n",
      "ive\n",
      "been\n",
      "without\n",
      "it\n",
      "for\n",
      "week\n",
      "at\n",
      "least\n",
      ",\n",
      "and\n",
      "suddenli\n",
      "it\n",
      "come\n",
      "up\n",
      "today\n",
      "and\n",
      "it\n",
      "realli\n",
      "freak\n",
      "me\n",
      "out\n",
      ".\n",
      "ani\n",
      "gener\n",
      "advic\n",
      "on\n",
      "how\n",
      "to\n",
      "...\n",
      "I\n",
      "forgot\n",
      "I\n",
      "made\n",
      "thi\n",
      "thread\n",
      "...\n",
      "the\n",
      "empti\n",
      "feel\n",
      "subsid\n",
      ".\n",
      "but\n",
      "one\n",
      "morn\n",
      "I\n",
      "woke\n",
      "up\n",
      "in\n",
      "extrem\n",
      "tension\n",
      "and\n",
      "decid\n",
      "it\n",
      "wa\n",
      "time\n",
      "to\n",
      "get\n",
      "in\n",
      "contact\n",
      "with\n",
      "my\n",
      "birth\n",
      "mother\n",
      ".\n",
      "So\n",
      "I\n",
      "found\n",
      "her\n",
      "info\n",
      "...\n",
      "wtf\n",
      "do\n",
      "I\n",
      "do\n",
      "?\n",
      "almost\n",
      "everi\n",
      "day\n",
      ",\n",
      "I\n",
      "am\n",
      "lose\n",
      "my\n",
      "shit\n",
      "with\n",
      "anxieti\n",
      "that\n",
      "Im\n",
      "go\n",
      "to\n",
      "develop\n",
      "schizophrenia\n",
      ",\n",
      "or\n",
      "bipolar\n",
      ",\n",
      "or\n",
      "borderlin\n",
      ",\n",
      "or\n",
      "whatev\n",
      ".\n",
      "I\n",
      "recent\n",
      "wa\n",
      "evalu\n",
      "through\n",
      "the\n",
      "mmpi-ii\n",
      "by\n",
      "my\n",
      "...\n",
      "addictivemus\n",
      "Im\n",
      "glad\n",
      "someon\n",
      "understand\n",
      "my\n",
      "percept\n",
      "of\n",
      "emot\n",
      ".\n",
      "haha\n",
      ".\n",
      "mean\n",
      "Im\n",
      "not\n",
      "complet\n",
      "off\n",
      "or\n",
      "strang\n",
      ",\n",
      "I\n",
      "suppos\n",
      ".\n",
      "thank\n",
      "for\n",
      "the\n",
      "respons\n",
      ".\n",
      ":\n",
      "-\n",
      ")\n",
      "I\n",
      "cant\n",
      "tell\n",
      "if\n",
      "it\n",
      "is\n",
      "empti\n",
      ",\n",
      "restless\n",
      ",\n",
      "anxieti\n",
      ",\n",
      "sad\n",
      ",\n",
      "or\n",
      "what\n",
      ".\n",
      "like\n",
      "I\n",
      "said\n",
      ",\n",
      "it\n",
      "weird\n",
      ",\n",
      "becaus\n",
      "usual\n",
      "I\n",
      "understand\n",
      "emot\n",
      "realli\n",
      "well\n",
      ".\n",
      "it\n",
      "just\n",
      "thi\n",
      "...\n",
      "So\n",
      "late\n",
      "ive\n",
      "been\n",
      "have\n",
      "thi\n",
      "occasion\n",
      "feel\n",
      "of\n",
      "empti\n",
      ".\n",
      "that\n",
      "is\n",
      "quit\n",
      "unusu\n",
      "for\n",
      "me\n",
      ".\n",
      "even\n",
      "when\n",
      "Id\n",
      "get\n",
      "depress\n",
      ",\n",
      "Id\n",
      "be\n",
      "feel\n",
      "quit\n",
      "a\n",
      "lot\n",
      ".\n",
      "It\n",
      "wa\n",
      "just\n",
      "all\n",
      "bad\n",
      "thing\n",
      "-\n",
      "mostli\n",
      "...\n",
      "I\n",
      "have\n",
      "had\n",
      "a\n",
      "deep\n",
      "love\n",
      "for\n",
      "elliott\n",
      "smith\n",
      "music\n",
      "and\n",
      "what\n",
      "I\n",
      "understand\n",
      "about\n",
      "him\n",
      "as\n",
      "a\n",
      "human\n",
      "be\n",
      "for\n",
      "sever\n",
      "year\n",
      "now\n",
      ".\n",
      "what\n",
      "are\n",
      "some\n",
      "of\n",
      "your\n",
      "favorit\n",
      "song\n",
      "of\n",
      "hi\n",
      "?\n",
      "I\n",
      "post\n",
      "in\n",
      "thi\n",
      "thread\n",
      "over\n",
      "a\n",
      "year\n",
      "ago\n",
      "but\n",
      "I\n",
      "am\n",
      "go\n",
      "to\n",
      "again\n",
      ".\n",
      "sinc\n",
      "that\n",
      "post\n",
      ",\n",
      "I\n",
      "have\n",
      "recogn\n",
      "that\n",
      "I\n",
      "am\n",
      "infp\n",
      "6w5\n",
      ".\n",
      "I\n",
      "have\n",
      "also\n",
      "recogn\n",
      "the\n",
      "extent\n",
      "to\n",
      "which\n",
      "be\n",
      "adopt\n",
      "and\n",
      "abus\n",
      "ha\n",
      "...\n",
      "thi\n",
      "is\n",
      "a\n",
      "three\n",
      "year\n",
      "old\n",
      "post\n",
      ",\n",
      "but\n",
      "I\n",
      "just\n",
      "came\n",
      "across\n",
      "it\n",
      "and\n",
      "it\n",
      "is\n",
      "veri\n",
      "inspir\n",
      "to\n",
      "me\n",
      ".\n",
      ":\n",
      "-\n",
      ")\n",
      "the\n",
      "boy\n",
      "laid\n",
      "awak\n",
      "for\n",
      "nine\n",
      "hour\n",
      "after\n",
      "bedtim\n",
      "memori\n",
      "of\n",
      "the\n",
      "day\n",
      "twist\n",
      "themselv\n",
      "round\n",
      "hi\n",
      "chest\n",
      "each\n",
      "detail\n",
      "bastard\n",
      "with\n",
      "the\n",
      "bent\n",
      "of\n",
      "person\n",
      "respons\n",
      "jag\n",
      ",\n",
      "rust\n",
      "memori\n",
      "...\n",
      "thi\n",
      "is\n",
      "silli\n",
      ",\n",
      "but\n",
      "it\n",
      "troubl\n",
      "me\n",
      "that\n",
      "daniel\n",
      "johnston\n",
      "had\n",
      "a\n",
      "psychot\n",
      "break\n",
      "and\n",
      "is\n",
      "perceiv\n",
      "to\n",
      "be\n",
      "4w3/6w5\n",
      ",\n",
      "becaus\n",
      "I\n",
      "am\n",
      "infp\n",
      "6w5\n",
      "4w3\n",
      "and\n",
      "have\n",
      "had\n",
      "a\n",
      "lifelong\n",
      "phobia\n",
      "of\n",
      "lose\n",
      "my\n",
      "mind\n",
      ".\n",
      "I\n",
      "know\n",
      "it\n",
      "...\n",
      "sad\n",
      "is\n",
      "the\n",
      "light\n",
      "all\n",
      "off\n",
      "after\n",
      "6:30\n",
      "pm\n",
      "on\n",
      "a\n",
      "dull\n",
      "winter\n",
      "day\n",
      "the\n",
      "quiet\n",
      "crust\n",
      "on\n",
      "the\n",
      "kitchen\n",
      "floor\n",
      "unkempt\n",
      "hair\n",
      "and\n",
      "toenail\n",
      "pile\n",
      "of\n",
      "rubbish\n",
      ";\n",
      "tissu\n",
      "and\n",
      "cellophan\n",
      "besid\n",
      "my\n",
      "bed\n",
      "heap\n",
      "of\n",
      "...\n",
      "I\n",
      "might\n",
      "say\n",
      "more\n",
      "later\n",
      "but\n",
      "what\n",
      "I\n",
      "notic\n",
      "right\n",
      "now\n",
      "in\n",
      "think\n",
      "about\n",
      "myself\n",
      "and\n",
      "intp\n",
      "I\n",
      "know\n",
      "is\n",
      "that\n",
      "intp\n",
      "are\n",
      "ever\n",
      "hungri\n",
      "for\n",
      "more\n",
      "knowledg\n",
      ".\n",
      "My\n",
      "intp\n",
      "roommat\n",
      "say\n",
      "she\n",
      "could\n",
      "read\n",
      "thousand\n",
      "of\n",
      "book\n",
      "...\n",
      "thi\n",
      "comput\n",
      "did\n",
      "a\n",
      "weird\n",
      "one\n",
      "and\n",
      "somehow\n",
      "made\n",
      "a\n",
      "doubl\n",
      "post\n",
      "...\n",
      "I\n",
      "realli\n",
      "admir\n",
      "that\n",
      "abil\n",
      "for\n",
      "hold\n",
      "multipl\n",
      "perspect\n",
      "at\n",
      "onc\n",
      "while\n",
      "not\n",
      "be\n",
      "limit\n",
      "by\n",
      "feel\n",
      ".\n",
      ":\n",
      "-\n",
      ")\n",
      "I\n",
      "do\n",
      "see\n",
      "Fi\n",
      "as\n",
      "valuabl\n",
      ".\n",
      "I\n",
      "just\n",
      ",\n",
      "perhap\n",
      ",\n",
      "have\n",
      "some\n",
      "tness\n",
      "envi\n",
      "and\n",
      "want\n",
      "to\n",
      "hone\n",
      "my\n",
      "...\n",
      "be\n",
      "an\n",
      "infp\n",
      ",\n",
      "I\n",
      "understand\n",
      "what\n",
      "you\n",
      "mean\n",
      ".\n",
      "I\n",
      "have\n",
      "been\n",
      "date\n",
      "an\n",
      "entj\n",
      "for\n",
      "over\n",
      "a\n",
      "year\n",
      ",\n",
      "and\n",
      "while\n",
      "I\n",
      "alway\n",
      "understand\n",
      "her\n",
      "logic\n",
      ",\n",
      "and\n",
      "match\n",
      "her\n",
      "analyt\n",
      "abil\n",
      "most\n",
      "of\n",
      "the\n",
      "time\n",
      ",\n",
      "it\n",
      "ha\n",
      "been\n",
      "an\n",
      "...\n",
      "I\n",
      "also\n",
      "vote\n",
      "that\n",
      "thi\n",
      "thread\n",
      "get\n",
      "sticki\n",
      ".\n",
      "It\n",
      "is\n",
      "veri\n",
      "neat\n",
      "and\n",
      "concis\n",
      ".\n",
      "and\n",
      ",\n",
      "of\n",
      "cours\n",
      ",\n",
      "the\n",
      "summ\n",
      "descript\n",
      "appear\n",
      "to\n",
      "be\n",
      "veri\n",
      "accur\n",
      ".\n",
      "I\n",
      "hate\n",
      "to\n",
      "do\n",
      "thi\n",
      "again\n",
      ",\n",
      "and\n",
      "thi\n",
      "will\n",
      "be\n",
      "the\n",
      "last\n",
      "time\n",
      "I\n",
      "ask\n",
      "for\n",
      "it\n",
      ",\n",
      "but\n",
      "I\n",
      "realli\n",
      "do\n",
      "not\n",
      "like\n",
      "the\n",
      "way\n",
      "my\n",
      "usernam\n",
      "look\n",
      "with\n",
      "the\n",
      "capit\n",
      "I\n",
      ".\n",
      "So\n",
      ",\n",
      "I\n",
      "would\n",
      "like\n",
      "my\n",
      "name\n",
      "to\n",
      "henceforth\n",
      "be\n",
      "...\n",
      "infj\n",
      "are\n",
      "such\n",
      "beauti\n",
      "peopl\n",
      "...\n",
      "they\n",
      "are\n",
      "far\n",
      "and\n",
      "away\n",
      "the\n",
      "most\n",
      "true\n",
      ",\n",
      "love\n",
      ",\n",
      "earnest\n",
      "peopl\n",
      "ive\n",
      "met\n",
      ".\n",
      "My\n",
      "adopt\n",
      "father\n",
      "is\n",
      "an\n",
      "infj\n",
      "and\n",
      "I\n",
      "have\n",
      "never\n",
      "known\n",
      "or\n",
      "conceiv\n",
      "of\n",
      "a\n",
      "more\n",
      "respect\n",
      "and\n",
      "...\n",
      "there\n",
      "certainli\n",
      "much\n",
      "potenti\n",
      "for\n",
      "that\n",
      "sort\n",
      "of\n",
      "pair\n",
      "to\n",
      "blow\n",
      "up\n",
      ".\n",
      "the\n",
      "infp\n",
      "often\n",
      "ha\n",
      "an\n",
      "issu\n",
      "with\n",
      "feel\n",
      "control\n",
      "(\n",
      "or\n",
      "mayb\n",
      "that\n",
      "just\n",
      "me\n",
      ")\n",
      "and\n",
      "becom\n",
      "moodi\n",
      ",\n",
      "which\n",
      "the\n",
      "entj\n",
      "doesnt\n",
      "...\n",
      "weird\n",
      ",\n",
      "that\n",
      "like\n",
      "my\n",
      "partner\n",
      "and\n",
      "me\n",
      ".\n",
      "I\n",
      "alway\n",
      "thought\n",
      "it\n",
      "wa\n",
      "a\n",
      "win\n",
      "sort\n",
      "of\n",
      "match\n",
      ",\n",
      "as\n",
      "uniqu\n",
      "as\n",
      "it\n",
      "is\n",
      ".\n",
      "My\n",
      "entj\n",
      "girlfriend\n",
      "is\n",
      "13\n",
      "year\n",
      "older\n",
      "than\n",
      "me\n",
      ".\n",
      "It\n",
      "is\n",
      "interest\n",
      "and\n",
      "feel\n",
      "veri\n",
      "natur\n",
      ".\n",
      "famou\n",
      "infp\n",
      "-\n",
      "celebritytypes.com\n",
      "loui\n",
      "c.k\n",
      ".\n",
      ":\n",
      "with\n",
      "movi\n",
      ",\n",
      "[\n",
      "what\n",
      "]\n",
      "I\n",
      "realli\n",
      "love\n",
      "[\n",
      "wa\n",
      "]\n",
      "moment\n",
      "and\n",
      "tone\n",
      "and\n",
      "feel\n",
      "in\n",
      "a\n",
      "scene\n",
      ",\n",
      "and\n",
      "I\n",
      "love\n",
      "creat\n",
      "those\n",
      ".\n",
      "loui\n",
      "c.k\n",
      ".\n",
      ":\n",
      "I\n",
      "never\n",
      "view\n",
      "...\n",
      "loui\n",
      "CK\n",
      "is\n",
      "a\n",
      "rage\n",
      "infp\n",
      ".\n",
      "http\n",
      ":\n",
      "//www.youtube.com/watch\n",
      "?\n",
      "v=5hbyscltf1c\n",
      "#\n",
      "t=239\n",
      "listen\n",
      "to\n",
      "him\n",
      "describ\n",
      "the\n",
      "feel\n",
      ".\n",
      "listen\n",
      "to\n",
      "it\n",
      ".\n",
      "I\n",
      "connect\n",
      "with\n",
      "what\n",
      "he\n",
      "wa\n",
      "say\n",
      "so\n",
      "much\n",
      "that\n",
      "I\n",
      "actual\n",
      "...\n",
      "I\n",
      "agre\n",
      "with\n",
      "you\n",
      ",\n",
      "on\n",
      "the\n",
      "surfac\n",
      "it\n",
      "doesnt\n",
      "make\n",
      "much\n",
      "sens\n",
      "what\n",
      "she\n",
      "do\n",
      ".\n",
      "she\n",
      "an\n",
      "entj\n",
      "and\n",
      "is\n",
      "protect\n",
      "of\n",
      "herself\n",
      "and\n",
      "doesnt\n",
      "do\n",
      "well\n",
      "with\n",
      "have\n",
      "to\n",
      "constantli\n",
      "dole\n",
      "out\n",
      "emot\n",
      ".\n",
      "but\n",
      "she\n",
      "ha\n",
      "...\n",
      "hello\n",
      "all\n",
      ",\n",
      "ive\n",
      "mention\n",
      "my\n",
      "ptsd\n",
      "here\n",
      "a\n",
      "coupl\n",
      "time\n",
      "but\n",
      "never\n",
      "so\n",
      "complet\n",
      ".\n",
      "I\n",
      "will\n",
      "do\n",
      "so\n",
      "now\n",
      ".\n",
      "I\n",
      "hope\n",
      "the\n",
      "process\n",
      "of\n",
      "type\n",
      "through\n",
      "everyth\n",
      "prove\n",
      "valuabl\n",
      ".\n",
      "I\n",
      "would\n",
      "like\n",
      "thi\n",
      "thread\n",
      "to\n",
      "be\n",
      "...\n",
      "I\n",
      "would\n",
      "like\n",
      "my\n",
      "name\n",
      "to\n",
      "be\n",
      "chang\n",
      "to\n",
      "intrsrchng\n",
      ".\n",
      "thank\n",
      "you\n",
      ".\n",
      "that\n",
      "is\n",
      "a\n",
      "good\n",
      "point\n",
      ",\n",
      "Te\n",
      "is\n",
      "actual\n",
      "someth\n",
      "I\n",
      "am\n",
      "work\n",
      "on\n",
      ".\n",
      "ive\n",
      "notic\n",
      "thi\n",
      "nasti\n",
      "tendenc\n",
      "of\n",
      "mine\n",
      "to\n",
      "constantli\n",
      "ponder\n",
      "mean\n",
      ".\n",
      "If\n",
      "I\n",
      "go\n",
      "for\n",
      "a\n",
      "walk\n",
      ",\n",
      "my\n",
      "mind\n",
      "immedi\n",
      "begin\n",
      "grind\n",
      "at\n",
      "what\n",
      "...\n",
      "mani\n",
      "infp\n",
      "becom\n",
      "domin\n",
      "by\n",
      "their\n",
      "Fi\n",
      ",\n",
      "such\n",
      "that\n",
      "they\n",
      "are\n",
      "hypersensit\n",
      ",\n",
      "irrat\n",
      ",\n",
      "and\n",
      "isol\n",
      ".\n",
      "while\n",
      "I\n",
      "certainli\n",
      "have\n",
      "a\n",
      "long\n",
      "way\n",
      "to\n",
      "go\n",
      "in\n",
      "my\n",
      "person\n",
      "develop\n",
      ",\n",
      "I\n",
      "have\n",
      "found\n",
      "the\n",
      "world\n",
      "much\n",
      "...\n",
      "Am\n",
      "still\n",
      "with\n",
      "thi\n",
      "girl\n",
      ",\n",
      "one\n",
      "year\n",
      "later\n",
      ".\n",
      "met\n",
      "on\n",
      "youtub\n",
      ";\n",
      "she\n",
      "saw\n",
      "my\n",
      "old\n",
      "channel\n",
      "and\n",
      "sent\n",
      "me\n",
      "a\n",
      "long\n",
      ",\n",
      "pretti\n",
      "perplexingli\n",
      "emo\n",
      "messag\n",
      ".\n",
      "We\n",
      "are\n",
      "perfect\n",
      "for\n",
      "each\n",
      "other\n",
      ".\n",
      "also\n",
      ",\n",
      "turn\n",
      "out\n",
      "we\n",
      "were\n",
      "both\n",
      "...\n",
      "wow\n",
      ",\n",
      "no\n",
      "dream\n",
      ",\n",
      "you\n",
      "say\n",
      "?\n",
      "I\n",
      "am\n",
      "veri\n",
      "curiou\n",
      "about\n",
      "thi\n",
      "imagin\n",
      "control\n",
      "you\n",
      "speak\n",
      "of\n",
      ".\n",
      "without\n",
      "be\n",
      "nosey\n",
      ",\n",
      "Im\n",
      "wonder\n",
      "what\n",
      "your\n",
      "intent\n",
      "is\n",
      "with\n",
      "mitig\n",
      "that\n",
      ".\n",
      "also\n",
      ",\n",
      "Im\n",
      "wonder\n",
      "if\n",
      "youv\n",
      "...\n",
      "well\n",
      ",\n",
      "it\n",
      "doe\n",
      "immedi\n",
      "make\n",
      "sens\n",
      "to\n",
      "me\n",
      "that\n",
      "thi\n",
      "issu\n",
      "is\n",
      "just\n",
      "hypervigil\n",
      ".\n",
      "and\n",
      "sinc\n",
      "I\n",
      "dont\n",
      "usual\n",
      "have\n",
      "anyth\n",
      "even\n",
      "remot\n",
      "danger\n",
      "in\n",
      "my\n",
      "life\n",
      ",\n",
      "my\n",
      "hypervigil\n",
      "react\n",
      "constantli\n",
      "to\n",
      "...\n",
      "ye\n",
      ",\n",
      "I\n",
      "actual\n",
      "do\n",
      "have\n",
      "ptsd\n",
      ".\n",
      "while\n",
      "I\n",
      "typic\n",
      "shi\n",
      "away\n",
      "from\n",
      "appli\n",
      "mental\n",
      "ill\n",
      "or\n",
      "person\n",
      "disord\n",
      "cluster\n",
      "to\n",
      "person\n",
      "type\n",
      ",\n",
      "Im\n",
      "wonder\n",
      "how\n",
      "mani\n",
      "other\n",
      "infp\n",
      "folk\n",
      "here\n",
      "experi\n",
      "thi\n",
      "sort\n",
      "of\n",
      "constant\n",
      "anxieti\n",
      "...\n",
      "ill\n",
      "chime\n",
      "in\n",
      "a\n",
      "bit\n",
      "late\n",
      "here\n",
      "as\n",
      "an\n",
      "infp\n",
      "just\n",
      "to\n",
      "say\n",
      "that\n",
      "ive\n",
      "been\n",
      "read\n",
      "through\n",
      "thi\n",
      "thread\n",
      "in\n",
      "a\n",
      "public\n",
      "cafe\n",
      ",\n",
      "listen\n",
      "to\n",
      "fake\n",
      "plastic\n",
      "tree\n",
      "by\n",
      "radiohead\n",
      ",\n",
      "and\n",
      "fight\n",
      "back\n",
      "all\n",
      "my\n",
      "emo\n",
      "tear\n",
      "...\n",
      "I\n",
      "get\n",
      "so\n",
      "mani\n",
      "like\n",
      "for\n",
      "thi\n",
      "comment\n",
      "and\n",
      "it\n",
      "turn\n",
      "out\n",
      "Im\n",
      "not\n",
      "even\n",
      "an\n",
      "intp\n",
      ".\n",
      "huahuahua\n",
      "internet\n",
      "typolog\n",
      "stuff\n",
      "seem\n",
      "more\n",
      "and\n",
      "more\n",
      "over\n",
      "the\n",
      "year\n",
      "to\n",
      "be\n",
      "just\n",
      "a\n",
      "bunch\n",
      "of\n",
      "peopl\n",
      "look\n",
      "for\n",
      "neato\n",
      "...\n",
      "your\n",
      "alreadi\n",
      "here\n",
      ",\n",
      "youll\n",
      "die\n",
      "anyway\n",
      ",\n",
      "so\n",
      "I\n",
      "guess\n",
      "one\n",
      "might\n",
      "as\n",
      "well\n",
      "stick\n",
      "around\n",
      "and\n",
      "see\n",
      "if\n",
      "anyth\n",
      "interest\n",
      "happen\n",
      ".\n",
      "also\n",
      ",\n",
      "I\n",
      "believ\n",
      "that\n",
      "serious\n",
      "entertain\n",
      "suicid\n",
      "and\n",
      "follow\n",
      "that\n",
      "...\n",
      "Hi\n",
      "all\n",
      ",\n",
      "I\n",
      "use\n",
      "to\n",
      "roam\n",
      "these\n",
      "intp\n",
      "part\n",
      "for\n",
      "about\n",
      "a\n",
      "year\n",
      "(\n",
      "most\n",
      "of\n",
      "my\n",
      "post\n",
      "are\n",
      "in\n",
      "here\n",
      ")\n",
      "and\n",
      "I\n",
      "seem\n",
      "to\n",
      "gener\n",
      "get\n",
      "along\n",
      "veri\n",
      "well\n",
      "with\n",
      "intp\n",
      ".\n",
      "I\n",
      "appreci\n",
      "your\n",
      "logic\n",
      "deduct\n",
      "and\n",
      "honest\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for post in train_df['new_posts'][0]:\n",
    "    for word in word_tokenize(post):\n",
    "        print(ps.stem(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ne</th>\n",
       "      <th>Ni</th>\n",
       "      <th>Se</th>\n",
       "      <th>Si</th>\n",
       "      <th>Fi</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Ti</th>\n",
       "      <th>Te</th>\n",
       "      <th>E</th>\n",
       "      <th>Qmarks</th>\n",
       "      <th>...</th>\n",
       "      <th>shortened</th>\n",
       "      <th>ext</th>\n",
       "      <th>feeling</th>\n",
       "      <th>thinking</th>\n",
       "      <th>ok_vars</th>\n",
       "      <th>short_gratitude</th>\n",
       "      <th>fancy</th>\n",
       "      <th>love_words</th>\n",
       "      <th>other_laugh</th>\n",
       "      <th>third_laugh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ne</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.141392</td>\n",
       "      <td>-0.010853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>0.040953</td>\n",
       "      <td>0.051916</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.055399</td>\n",
       "      <td>0.062501</td>\n",
       "      <td>0.085455</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.021768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ni</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.096310</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035589</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>-0.010190</td>\n",
       "      <td>-0.036716</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>-0.040408</td>\n",
       "      <td>-0.005322</td>\n",
       "      <td>-0.039057</td>\n",
       "      <td>-0.006719</td>\n",
       "      <td>-0.002741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Se</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.018442</td>\n",
       "      <td>0.050265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.018736</td>\n",
       "      <td>-0.020528</td>\n",
       "      <td>-0.017777</td>\n",
       "      <td>-0.044980</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>-0.031582</td>\n",
       "      <td>-0.017729</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>-0.010296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.026639</td>\n",
       "      <td>-0.038209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023915</td>\n",
       "      <td>-0.014083</td>\n",
       "      <td>-0.010235</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>-0.020525</td>\n",
       "      <td>-0.025597</td>\n",
       "      <td>-0.028669</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>-0.008730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fi</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.002049</td>\n",
       "      <td>-0.019084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041002</td>\n",
       "      <td>0.143927</td>\n",
       "      <td>0.197399</td>\n",
       "      <td>0.082494</td>\n",
       "      <td>-0.020226</td>\n",
       "      <td>0.058550</td>\n",
       "      <td>0.058292</td>\n",
       "      <td>0.196192</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.028385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fe</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.063524</td>\n",
       "      <td>-0.059358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>0.102924</td>\n",
       "      <td>0.125017</td>\n",
       "      <td>0.046274</td>\n",
       "      <td>-0.002195</td>\n",
       "      <td>-0.019606</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.091479</td>\n",
       "      <td>0.073191</td>\n",
       "      <td>0.015848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ti</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.058496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029327</td>\n",
       "      <td>-0.127461</td>\n",
       "      <td>-0.176974</td>\n",
       "      <td>-0.048355</td>\n",
       "      <td>-0.015500</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>-0.027373</td>\n",
       "      <td>-0.128466</td>\n",
       "      <td>-0.036515</td>\n",
       "      <td>-0.016913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Te</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059426</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021799</td>\n",
       "      <td>-0.119391</td>\n",
       "      <td>-0.145442</td>\n",
       "      <td>-0.080413</td>\n",
       "      <td>0.037921</td>\n",
       "      <td>-0.041326</td>\n",
       "      <td>-0.036918</td>\n",
       "      <td>-0.159205</td>\n",
       "      <td>-0.076944</td>\n",
       "      <td>-0.027320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.141392</td>\n",
       "      <td>-0.096310</td>\n",
       "      <td>-0.018442</td>\n",
       "      <td>-0.026639</td>\n",
       "      <td>-0.002049</td>\n",
       "      <td>-0.063524</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>-0.059426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023650</td>\n",
       "      <td>-0.041306</td>\n",
       "      <td>-0.082714</td>\n",
       "      <td>-0.013982</td>\n",
       "      <td>-0.005517</td>\n",
       "      <td>0.034466</td>\n",
       "      <td>-0.002975</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>0.030025</td>\n",
       "      <td>0.036455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qmarks</th>\n",
       "      <td>-0.010853</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>0.050265</td>\n",
       "      <td>-0.038209</td>\n",
       "      <td>-0.019084</td>\n",
       "      <td>-0.059358</td>\n",
       "      <td>0.058496</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058446</td>\n",
       "      <td>-0.159134</td>\n",
       "      <td>-0.085656</td>\n",
       "      <td>-0.025516</td>\n",
       "      <td>0.056385</td>\n",
       "      <td>-0.012051</td>\n",
       "      <td>-0.015789</td>\n",
       "      <td>0.038594</td>\n",
       "      <td>-0.014023</td>\n",
       "      <td>0.029306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commas</th>\n",
       "      <td>0.058492</td>\n",
       "      <td>-0.018354</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>-0.035621</td>\n",
       "      <td>0.030890</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.023085</td>\n",
       "      <td>-0.067052</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>-0.140517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024734</td>\n",
       "      <td>0.122980</td>\n",
       "      <td>0.024911</td>\n",
       "      <td>0.010874</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.028993</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>0.048496</td>\n",
       "      <td>0.029077</td>\n",
       "      <td>-0.003872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclamations</th>\n",
       "      <td>0.008207</td>\n",
       "      <td>-0.001586</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>0.014831</td>\n",
       "      <td>0.110819</td>\n",
       "      <td>0.081575</td>\n",
       "      <td>-0.124064</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>0.089655</td>\n",
       "      <td>0.035434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086554</td>\n",
       "      <td>0.059297</td>\n",
       "      <td>0.031506</td>\n",
       "      <td>-0.048214</td>\n",
       "      <td>0.033815</td>\n",
       "      <td>-0.005130</td>\n",
       "      <td>0.051301</td>\n",
       "      <td>0.213024</td>\n",
       "      <td>0.182012</td>\n",
       "      <td>0.054636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first person</th>\n",
       "      <td>0.001363</td>\n",
       "      <td>-0.090891</td>\n",
       "      <td>0.022605</td>\n",
       "      <td>0.066923</td>\n",
       "      <td>0.145768</td>\n",
       "      <td>0.099167</td>\n",
       "      <td>-0.121800</td>\n",
       "      <td>-0.123135</td>\n",
       "      <td>-0.044506</td>\n",
       "      <td>-0.187234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.273342</td>\n",
       "      <td>0.283148</td>\n",
       "      <td>0.111274</td>\n",
       "      <td>-0.062269</td>\n",
       "      <td>-0.036632</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.234985</td>\n",
       "      <td>0.156376</td>\n",
       "      <td>0.016841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second person</th>\n",
       "      <td>-0.034749</td>\n",
       "      <td>0.078321</td>\n",
       "      <td>-0.010076</td>\n",
       "      <td>-0.033496</td>\n",
       "      <td>-0.067146</td>\n",
       "      <td>-0.032072</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>0.076896</td>\n",
       "      <td>0.099651</td>\n",
       "      <td>0.121550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008593</td>\n",
       "      <td>-0.122733</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>-0.007985</td>\n",
       "      <td>0.033939</td>\n",
       "      <td>0.039163</td>\n",
       "      <td>0.026903</td>\n",
       "      <td>-0.026024</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>-0.012435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop culture</th>\n",
       "      <td>-0.032975</td>\n",
       "      <td>-0.051555</td>\n",
       "      <td>0.065750</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>0.066732</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>-0.033957</td>\n",
       "      <td>-0.070826</td>\n",
       "      <td>0.116630</td>\n",
       "      <td>-0.028109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031780</td>\n",
       "      <td>-0.009396</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.018190</td>\n",
       "      <td>-0.007776</td>\n",
       "      <td>-0.043287</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>0.042724</td>\n",
       "      <td>0.018457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud words</th>\n",
       "      <td>0.001425</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>0.049614</td>\n",
       "      <td>-0.004442</td>\n",
       "      <td>0.121737</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>-0.070698</td>\n",
       "      <td>-0.053374</td>\n",
       "      <td>0.037649</td>\n",
       "      <td>-0.042625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026472</td>\n",
       "      <td>0.194873</td>\n",
       "      <td>0.208933</td>\n",
       "      <td>0.100737</td>\n",
       "      <td>-0.029466</td>\n",
       "      <td>-0.000908</td>\n",
       "      <td>-0.031990</td>\n",
       "      <td>0.086515</td>\n",
       "      <td>0.067940</td>\n",
       "      <td>0.049552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_words</th>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.055202</td>\n",
       "      <td>-0.056770</td>\n",
       "      <td>-0.001941</td>\n",
       "      <td>-0.022630</td>\n",
       "      <td>0.016364</td>\n",
       "      <td>-0.030630</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>-0.003258</td>\n",
       "      <td>-0.275011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057991</td>\n",
       "      <td>0.221556</td>\n",
       "      <td>0.181726</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>-0.090654</td>\n",
       "      <td>-0.017027</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.037388</td>\n",
       "      <td>0.041801</td>\n",
       "      <td>-0.058283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang</th>\n",
       "      <td>-0.016957</td>\n",
       "      <td>-0.003823</td>\n",
       "      <td>0.055438</td>\n",
       "      <td>-0.034658</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>-0.028293</td>\n",
       "      <td>-0.038988</td>\n",
       "      <td>0.047870</td>\n",
       "      <td>0.022064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007538</td>\n",
       "      <td>0.090450</td>\n",
       "      <td>0.042009</td>\n",
       "      <td>-0.003011</td>\n",
       "      <td>-0.002740</td>\n",
       "      <td>0.011903</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>0.037043</td>\n",
       "      <td>0.082707</td>\n",
       "      <td>-0.013724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortened</th>\n",
       "      <td>0.005441</td>\n",
       "      <td>-0.035589</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.023915</td>\n",
       "      <td>0.041002</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>-0.029327</td>\n",
       "      <td>-0.021799</td>\n",
       "      <td>-0.023650</td>\n",
       "      <td>0.058446</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018214</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>-0.016836</td>\n",
       "      <td>-0.014981</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>-0.005969</td>\n",
       "      <td>-0.004695</td>\n",
       "      <td>0.018282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ext</th>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>0.018736</td>\n",
       "      <td>-0.014083</td>\n",
       "      <td>0.143927</td>\n",
       "      <td>0.102924</td>\n",
       "      <td>-0.127461</td>\n",
       "      <td>-0.119391</td>\n",
       "      <td>-0.041306</td>\n",
       "      <td>-0.159134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018214</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221263</td>\n",
       "      <td>0.160369</td>\n",
       "      <td>-0.052884</td>\n",
       "      <td>0.084086</td>\n",
       "      <td>0.099423</td>\n",
       "      <td>0.133909</td>\n",
       "      <td>0.119405</td>\n",
       "      <td>-0.030198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feeling</th>\n",
       "      <td>0.040953</td>\n",
       "      <td>-0.010190</td>\n",
       "      <td>-0.020528</td>\n",
       "      <td>-0.010235</td>\n",
       "      <td>0.197399</td>\n",
       "      <td>0.125017</td>\n",
       "      <td>-0.176974</td>\n",
       "      <td>-0.145442</td>\n",
       "      <td>-0.082714</td>\n",
       "      <td>-0.085656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.221263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.121619</td>\n",
       "      <td>-0.025351</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>0.024078</td>\n",
       "      <td>0.175232</td>\n",
       "      <td>0.087002</td>\n",
       "      <td>0.009458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinking</th>\n",
       "      <td>0.051916</td>\n",
       "      <td>-0.036716</td>\n",
       "      <td>-0.017777</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.082494</td>\n",
       "      <td>0.046274</td>\n",
       "      <td>-0.048355</td>\n",
       "      <td>-0.080413</td>\n",
       "      <td>-0.013982</td>\n",
       "      <td>-0.025516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.160369</td>\n",
       "      <td>0.121619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037577</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>-0.009728</td>\n",
       "      <td>-0.028998</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>-0.002886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok_vars</th>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>-0.044980</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>-0.020226</td>\n",
       "      <td>-0.002195</td>\n",
       "      <td>-0.015500</td>\n",
       "      <td>0.037921</td>\n",
       "      <td>-0.005517</td>\n",
       "      <td>0.056385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016836</td>\n",
       "      <td>-0.052884</td>\n",
       "      <td>-0.025351</td>\n",
       "      <td>-0.037577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>0.019251</td>\n",
       "      <td>-0.004810</td>\n",
       "      <td>-0.035878</td>\n",
       "      <td>-0.001247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_gratitude</th>\n",
       "      <td>0.055399</td>\n",
       "      <td>-0.040408</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>-0.020525</td>\n",
       "      <td>0.058550</td>\n",
       "      <td>-0.019606</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>-0.041326</td>\n",
       "      <td>0.034466</td>\n",
       "      <td>-0.012051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014981</td>\n",
       "      <td>0.084086</td>\n",
       "      <td>-0.004786</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010888</td>\n",
       "      <td>-0.020430</td>\n",
       "      <td>-0.017816</td>\n",
       "      <td>-0.014801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fancy</th>\n",
       "      <td>0.062501</td>\n",
       "      <td>-0.005322</td>\n",
       "      <td>-0.031582</td>\n",
       "      <td>-0.025597</td>\n",
       "      <td>0.058292</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>-0.027373</td>\n",
       "      <td>-0.036918</td>\n",
       "      <td>-0.002975</td>\n",
       "      <td>-0.015789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.099423</td>\n",
       "      <td>0.024078</td>\n",
       "      <td>-0.009728</td>\n",
       "      <td>0.019251</td>\n",
       "      <td>0.010888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049720</td>\n",
       "      <td>0.070152</td>\n",
       "      <td>0.093199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love_words</th>\n",
       "      <td>0.085455</td>\n",
       "      <td>-0.039057</td>\n",
       "      <td>-0.017729</td>\n",
       "      <td>-0.028669</td>\n",
       "      <td>0.196192</td>\n",
       "      <td>0.091479</td>\n",
       "      <td>-0.128466</td>\n",
       "      <td>-0.159205</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>0.038594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005969</td>\n",
       "      <td>0.133909</td>\n",
       "      <td>0.175232</td>\n",
       "      <td>-0.028998</td>\n",
       "      <td>-0.004810</td>\n",
       "      <td>-0.020430</td>\n",
       "      <td>0.049720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063941</td>\n",
       "      <td>0.068335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_laugh</th>\n",
       "      <td>0.004354</td>\n",
       "      <td>-0.006719</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.073191</td>\n",
       "      <td>-0.036515</td>\n",
       "      <td>-0.076944</td>\n",
       "      <td>0.030025</td>\n",
       "      <td>-0.014023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004695</td>\n",
       "      <td>0.119405</td>\n",
       "      <td>0.087002</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>-0.035878</td>\n",
       "      <td>-0.017816</td>\n",
       "      <td>0.070152</td>\n",
       "      <td>0.063941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_laugh</th>\n",
       "      <td>0.021768</td>\n",
       "      <td>-0.002741</td>\n",
       "      <td>-0.010296</td>\n",
       "      <td>-0.008730</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.015848</td>\n",
       "      <td>-0.016913</td>\n",
       "      <td>-0.027320</td>\n",
       "      <td>0.036455</td>\n",
       "      <td>0.029306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018282</td>\n",
       "      <td>-0.030198</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>-0.002886</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>-0.014801</td>\n",
       "      <td>0.093199</td>\n",
       "      <td>0.068335</td>\n",
       "      <td>0.032542</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Ne        Ni        Se        Si        Fi        Fe  \\\n",
       "Ne               1.000000 -0.333333 -0.333333 -0.333333  0.333333 -0.333333   \n",
       "Ni              -0.333333  1.000000 -0.333333 -0.333333 -0.333333  0.333333   \n",
       "Se              -0.333333 -0.333333  1.000000 -0.333333  0.333333 -0.333333   \n",
       "Si              -0.333333 -0.333333 -0.333333  1.000000 -0.333333  0.333333   \n",
       "Fi               0.333333 -0.333333  0.333333 -0.333333  1.000000 -0.333333   \n",
       "Fe              -0.333333  0.333333 -0.333333  0.333333 -0.333333  1.000000   \n",
       "Ti               0.333333 -0.333333  0.333333 -0.333333 -0.333333 -0.333333   \n",
       "Te              -0.333333  0.333333 -0.333333  0.333333 -0.333333 -0.333333   \n",
       "E                0.141392 -0.096310 -0.018442 -0.026639 -0.002049 -0.063524   \n",
       "Qmarks          -0.010853 -0.001203  0.050265 -0.038209 -0.019084 -0.059358   \n",
       "commas           0.058492 -0.018354 -0.004517 -0.035621  0.030890  0.013077   \n",
       "exclamations     0.008207 -0.001586 -0.021452  0.014831  0.110819  0.081575   \n",
       "first person     0.001363 -0.090891  0.022605  0.066923  0.145768  0.099167   \n",
       "second person   -0.034749  0.078321 -0.010076 -0.033496 -0.067146 -0.032072   \n",
       "pop culture     -0.032975 -0.051555  0.065750  0.018780  0.066732  0.038051   \n",
       "cloud words      0.001425 -0.046597  0.049614 -0.004442  0.121737  0.002334   \n",
       "stop_words       0.003509  0.055202 -0.056770 -0.001941 -0.022630  0.016364   \n",
       "slang           -0.016957 -0.003823  0.055438 -0.034658  0.066774  0.000507   \n",
       "shortened        0.005441 -0.035589  0.006234  0.023915  0.041002  0.010124   \n",
       "ext             -0.002269 -0.002384  0.018736 -0.014083  0.143927  0.102924   \n",
       "feeling          0.040953 -0.010190 -0.020528 -0.010235  0.197399  0.125017   \n",
       "thinking         0.051916 -0.036716 -0.017777  0.002577  0.082494  0.046274   \n",
       "ok_vars          0.009253  0.009331 -0.044980  0.026395 -0.020226 -0.002195   \n",
       "short_gratitude  0.055399 -0.040408  0.005534 -0.020525  0.058550 -0.019606   \n",
       "fancy            0.062501 -0.005322 -0.031582 -0.025597  0.058292  0.005999   \n",
       "love_words       0.085455 -0.039057 -0.017729 -0.028669  0.196192  0.091479   \n",
       "other_laugh      0.004354 -0.006719 -0.000601  0.002966  0.040268  0.073191   \n",
       "third_laugh      0.021768 -0.002741 -0.010296 -0.008730  0.028385  0.015848   \n",
       "\n",
       "                       Ti        Te         E    Qmarks  ...  shortened  \\\n",
       "Ne               0.333333 -0.333333  0.141392 -0.010853  ...   0.005441   \n",
       "Ni              -0.333333  0.333333 -0.096310 -0.001203  ...  -0.035589   \n",
       "Se               0.333333 -0.333333 -0.018442  0.050265  ...   0.006234   \n",
       "Si              -0.333333  0.333333 -0.026639 -0.038209  ...   0.023915   \n",
       "Fi              -0.333333 -0.333333 -0.002049 -0.019084  ...   0.041002   \n",
       "Fe              -0.333333 -0.333333 -0.063524 -0.059358  ...   0.010124   \n",
       "Ti               1.000000 -0.333333  0.124999  0.058496  ...  -0.029327   \n",
       "Te              -0.333333  1.000000 -0.059426  0.019947  ...  -0.021799   \n",
       "E                0.124999 -0.059426  1.000000  0.020873  ...  -0.023650   \n",
       "Qmarks           0.058496  0.019947  0.020873  1.000000  ...   0.058446   \n",
       "commas           0.023085 -0.067052  0.006203 -0.140517  ...  -0.024734   \n",
       "exclamations    -0.124064 -0.068330  0.089655  0.035434  ...   0.086554   \n",
       "first person    -0.121800 -0.123135 -0.044506 -0.187234  ...   0.008501   \n",
       "second person    0.022322  0.076896  0.099651  0.121550  ...  -0.008593   \n",
       "pop culture     -0.033957 -0.070826  0.116630 -0.028109  ...   0.031780   \n",
       "cloud words     -0.070698 -0.053374  0.037649 -0.042625  ...   0.026472   \n",
       "stop_words      -0.030630  0.036896 -0.003258 -0.275011  ...  -0.057991   \n",
       "slang           -0.028293 -0.038988  0.047870  0.022064  ...  -0.007538   \n",
       "shortened       -0.029327 -0.021799 -0.023650  0.058446  ...   1.000000   \n",
       "ext             -0.127461 -0.119391 -0.041306 -0.159134  ...  -0.018214   \n",
       "feeling         -0.176974 -0.145442 -0.082714 -0.085656  ...   0.000294   \n",
       "thinking        -0.048355 -0.080413 -0.013982 -0.025516  ...   0.003944   \n",
       "ok_vars         -0.015500  0.037921 -0.005517  0.056385  ...  -0.016836   \n",
       "short_gratitude  0.002382 -0.041326  0.034466 -0.012051  ...  -0.014981   \n",
       "fancy           -0.027373 -0.036918 -0.002975 -0.015789  ...  -0.003520   \n",
       "love_words      -0.128466 -0.159205 -0.000978  0.038594  ...  -0.005969   \n",
       "other_laugh     -0.036515 -0.076944  0.030025 -0.014023  ...  -0.004695   \n",
       "third_laugh     -0.016913 -0.027320  0.036455  0.029306  ...   0.018282   \n",
       "\n",
       "                      ext   feeling  thinking   ok_vars  short_gratitude  \\\n",
       "Ne              -0.002269  0.040953  0.051916  0.009253         0.055399   \n",
       "Ni              -0.002384 -0.010190 -0.036716  0.009331        -0.040408   \n",
       "Se               0.018736 -0.020528 -0.017777 -0.044980         0.005534   \n",
       "Si              -0.014083 -0.010235  0.002577  0.026395        -0.020525   \n",
       "Fi               0.143927  0.197399  0.082494 -0.020226         0.058550   \n",
       "Fe               0.102924  0.125017  0.046274 -0.002195        -0.019606   \n",
       "Ti              -0.127461 -0.176974 -0.048355 -0.015500         0.002382   \n",
       "Te              -0.119391 -0.145442 -0.080413  0.037921        -0.041326   \n",
       "E               -0.041306 -0.082714 -0.013982 -0.005517         0.034466   \n",
       "Qmarks          -0.159134 -0.085656 -0.025516  0.056385        -0.012051   \n",
       "commas           0.122980  0.024911  0.010874  0.002523         0.028993   \n",
       "exclamations     0.059297  0.031506 -0.048214  0.033815        -0.005130   \n",
       "first person     0.273342  0.283148  0.111274 -0.062269        -0.036632   \n",
       "second person   -0.122733  0.008968 -0.007985  0.033939         0.039163   \n",
       "pop culture     -0.009396  0.011825  0.007358  0.018190        -0.007776   \n",
       "cloud words      0.194873  0.208933  0.100737 -0.029466        -0.000908   \n",
       "stop_words       0.221556  0.181726  0.030471 -0.090654        -0.017027   \n",
       "slang            0.090450  0.042009 -0.003011 -0.002740         0.011903   \n",
       "shortened       -0.018214  0.000294  0.003944 -0.016836        -0.014981   \n",
       "ext              1.000000  0.221263  0.160369 -0.052884         0.084086   \n",
       "feeling          0.221263  1.000000  0.121619 -0.025351        -0.004786   \n",
       "thinking         0.160369  0.121619  1.000000 -0.037577         0.004472   \n",
       "ok_vars         -0.052884 -0.025351 -0.037577  1.000000        -0.002550   \n",
       "short_gratitude  0.084086 -0.004786  0.004472 -0.002550         1.000000   \n",
       "fancy            0.099423  0.024078 -0.009728  0.019251         0.010888   \n",
       "love_words       0.133909  0.175232 -0.028998 -0.004810        -0.020430   \n",
       "other_laugh      0.119405  0.087002  0.031390 -0.035878        -0.017816   \n",
       "third_laugh     -0.030198  0.009458 -0.002886 -0.001247        -0.014801   \n",
       "\n",
       "                    fancy  love_words  other_laugh  third_laugh  \n",
       "Ne               0.062501    0.085455     0.004354     0.021768  \n",
       "Ni              -0.005322   -0.039057    -0.006719    -0.002741  \n",
       "Se              -0.031582   -0.017729    -0.000601    -0.010296  \n",
       "Si              -0.025597   -0.028669     0.002966    -0.008730  \n",
       "Fi               0.058292    0.196192     0.040268     0.028385  \n",
       "Fe               0.005999    0.091479     0.073191     0.015848  \n",
       "Ti              -0.027373   -0.128466    -0.036515    -0.016913  \n",
       "Te              -0.036918   -0.159205    -0.076944    -0.027320  \n",
       "E               -0.002975   -0.000978     0.030025     0.036455  \n",
       "Qmarks          -0.015789    0.038594    -0.014023     0.029306  \n",
       "commas           0.010651    0.048496     0.029077    -0.003872  \n",
       "exclamations     0.051301    0.213024     0.182012     0.054636  \n",
       "first person     0.009186    0.234985     0.156376     0.016841  \n",
       "second person    0.026903   -0.026024     0.002846    -0.012435  \n",
       "pop culture     -0.043287    0.061667     0.042724     0.018457  \n",
       "cloud words     -0.031990    0.086515     0.067940     0.049552  \n",
       "stop_words       0.007498    0.037388     0.041801    -0.058283  \n",
       "slang            0.034591    0.037043     0.082707    -0.013724  \n",
       "shortened       -0.003520   -0.005969    -0.004695     0.018282  \n",
       "ext              0.099423    0.133909     0.119405    -0.030198  \n",
       "feeling          0.024078    0.175232     0.087002     0.009458  \n",
       "thinking        -0.009728   -0.028998     0.031390    -0.002886  \n",
       "ok_vars          0.019251   -0.004810    -0.035878    -0.001247  \n",
       "short_gratitude  0.010888   -0.020430    -0.017816    -0.014801  \n",
       "fancy            1.000000    0.049720     0.070152     0.093199  \n",
       "love_words       0.049720    1.000000     0.063941     0.068335  \n",
       "other_laugh      0.070152    0.063941     1.000000     0.032542  \n",
       "third_laugh      0.093199    0.068335     0.032542     1.000000  \n",
       "\n",
       "[28 rows x 28 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df2 = train_df.drop(columns = ['post_list', 'links'])\n",
    "#train_df.corr()\n",
    "def find_high_corr(df):\n",
    "    corrs = []\n",
    "    done_already = []\n",
    "    length = len(df.columns) - 1\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            first = df.iloc[:,i]\n",
    "            second = df.iloc[:,j]\n",
    "            first_c = df.columns[i]\n",
    "            second_c = df.columns[j]\n",
    "            if([second_c,first_c] in done_already):\n",
    "                (\"Duplicate\")\n",
    "            else:\n",
    "                if(first_c == second_c):\n",
    "                    (\"Duplicate\")\n",
    "                else:\n",
    "                    if(first.dtype == 'O' or second.dtype == 'O'):\n",
    "                        (\"Not a number\")\n",
    "                    else:\n",
    "                        k = (f\"{first} - {second}\")\n",
    "                        v = first.corr(second)\n",
    "                        corrs.append([first_c,second_c,v])\n",
    "                done_already.append([first_c,second_c])\n",
    "    corr_df = pd.DataFrame(corrs,columns = [\"Factor 1\", \"Factor 2\", \"Correlation\"])\n",
    "    corr_df = corr_df.sort_values(\"Correlation\", ascending=False)\n",
    "    return corr_df\n",
    "\n",
    "corr_df = find_high_corr(train_df)\n",
    "#corr_df[corr_df['Factor 2'] == 'stop_words']\n",
    "train_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-295c000557cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mXo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    661\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    662\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = train_df.drop(['links','post_list','Fi','Fe','Ti','Te','Si','Se','Ni','Ne','E'], axis=1)\n",
    "y = train_df['E']\n",
    "\n",
    "X_train = train_df.drop(['links','post_list','Fi','Fe','Ti','Te','Si','Se','Ni','Ne','E'], axis=1)\n",
    "y_train = train_df['E']\n",
    "X_test = test_df.drop(['links','post_list','Fi','Fe','Ti','Te','Si','Se','Ni','Ne','E'], axis=1)\n",
    "y_test = test_df['E']\n",
    "\n",
    "Xo = X_train\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X_train)\n",
    "print(X)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# X_train = X\n",
    "# X_test = \n",
    "# y_train = y\n",
    "# y_test\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "p = clf.predict_proba(X_test)\n",
    "p = p[:,1]\n",
    "auc = roc_auc_score(y_test, p)\n",
    "print('AUC: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, p)\n",
    "plot_roc_curve(fpr, tpr)\n",
    "print(clf.feature_importances_)\n",
    "importances = clf.feature_importances_\n",
    "print(f\"Feature Importances{importances}\")\n",
    "std = np.std(importances, axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for i in indices:\n",
    "    print(f\"{Xo.columns[i]}\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test,p, average='macro'))\n",
    "print(f1_score(y_test,p, average='micro'))\n",
    "print(f1_score(y_test,p, average=None))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8d98dc9ae438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# training a Naive Bayes classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mgnb_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    191\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "    \n",
    "# X -> features, y -> label \n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 100) \n",
    "  \n",
    "# training a Naive Bayes classifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_train, y_train) \n",
    "gnb_predictions = gnb.predict(X_test) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = gnb.score(X_test, y_test) \n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, gnb_predictions) \n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, gnb_predictions, average='macro'))\n",
    "print(f1_score(y_test, gnb_predictions, average='micro'))\n",
    "print(f1_score(y_test, gnb_predictions, average='weighted'))\n",
    "print(f1_score(y_test, gnb_predictions, average=None))\n",
    "probs = gnb_predictions\n",
    "#probs = probs[:,1]\n",
    "# auc = roc_auc_score(y_test, probs)\n",
    "# #print('AUC: %.2f' % auc)\n",
    "\n",
    "p = gnb.predict_proba(X_test)\n",
    "p = p[:,1]\n",
    "auc = roc_auc_score(y_test, p)\n",
    "print('AUC: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, p)\n",
    "plot_roc_curve(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gnb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c28cbfd6d1a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mkfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results['test_acc']),\n\u001b[1;32m     10\u001b[0m                                                           np.std(results['test_acc'])))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gnb' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'neg_log_loss': 'neg_log_loss',\n",
    "           'f1_micro': 'f1_micro'}\n",
    "\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "results = cross_validate(gnb, X, y, scoring=scoring,cv=kfolds, n_jobs=-1)\n",
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results['test_acc']),\n",
    "                                                          np.std(results['test_acc'])))\n",
    "\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results['test_f1_micro']),\n",
    "                                                          np.std(results['test_f1_micro'])))\n",
    "\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results['test_neg_log_loss'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-34881dd21eee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df_new = train_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprincipalComponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \"\"\"\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 382\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.95)\n",
    "#df_new = train_df\n",
    "principalComponents = pca.fit_transform(Xo)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'principalComponents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-bc4b41ee96c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprincipalComponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'principalComponents' is not defined"
     ]
    }
   ],
   "source": [
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4d4528bb083e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# training a Naive Bayes classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mgnb_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    191\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "    \n",
    "# X -> features, y -> label \n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "#X_train, X_test, y_train, y_test = train_test_split(principalComponents, y, random_state = 100) \n",
    "\n",
    "# training a Naive Bayes classifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_train, y_train) \n",
    "gnb_predictions = gnb.predict(X_test) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = gnb.score(X_test, y_test) \n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, gnb_predictions) \n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, gnb_predictions, average='macro'))\n",
    "print(f1_score(y_test, gnb_predictions, average='micro'))\n",
    "print(f1_score(y_test, gnb_predictions, average='weighted'))\n",
    "print(f1_score(y_test, gnb_predictions, average=None))\n",
    "probs = gnb_predictions\n",
    "#probs = probs[:,1]\n",
    "# auc = roc_auc_score(y_test, probs)\n",
    "# #print('AUC: %.2f' % auc)\n",
    "\n",
    "p = gnb.predict_proba(X_test)\n",
    "p = p[:,1]\n",
    "auc = roc_auc_score(y_test, p)\n",
    "print('AUC: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, p)\n",
    "plot_roc_curve(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b5fb5c7f26cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# fit kmeans object to data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# print location of clusters learned by kmeans object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    970\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, sample_weight, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy_x\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[0;32m--> 309\u001b[0;31m                     order=order, copy=copy_x)\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# create kmeans object\n",
    "# import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "# fit kmeans object to data\n",
    "kmeans.fit(X)\n",
    "# print location of clusters learned by kmeans object\n",
    "print(kmeans.cluster_centers_)\n",
    "# save new clusters for chart\n",
    "y_km = kmeans.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_km' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-81fc650e0f48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_km\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_km\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_km\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_km\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_km\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_km\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_km\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_km\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cyan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_km' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(X[y_km ==0,0], X[y_km == 0,1], s=100, c='red')\n",
    "plt.scatter(X[y_km ==1,0], X[y_km == 1,1], s=100, c='black')\n",
    "plt.scatter(X[y_km ==2,0], X[y_km == 2,1], s=100, c='blue')\n",
    "plt.scatter(X[y_km ==3,0], X[y_km == 3,1], s=100, c='cyan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2b91795d002a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgglomerativeClustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdendrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdendrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinkage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# create clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mhc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgglomerativeClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffinity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinkage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/cluster/hierarchy.py\u001b[0m in \u001b[0;36mlinkage\u001b[0;34m(y, method, metric, optimal_ordering)\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid method: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_to_double\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/cluster/hierarchy.py\u001b[0m in \u001b[0;36m_convert_to_double\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_double\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# import hierarchical clustering libraries\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "dendrogram = sch.dendrogram(sch.linkage(X, method='ward'))\n",
    "# create clusters\n",
    "hc = AgglomerativeClustering(n_clusters=4, affinity = 'euclidean', linkage = 'ward')\n",
    "# save clusters for chart\n",
    "y_hc = hc.fit_predict(X)\n",
    "print(\"VO\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_hc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a1e8a936b8e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_hc\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_hc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_hc\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_hc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_hc\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_hc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_hc\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_hc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cyan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_hc' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(X[y_hc ==0,0], X[y_hc == 0,1], s=100, c='red')\n",
    "plt.scatter(X[y_hc==1,0], X[y_hc == 1,1], s=100, c='black')\n",
    "plt.scatter(X[y_hc ==2,0], X[y_hc == 2,1], s=100, c='blue')\n",
    "plt.scatter(X[y_hc ==3,0], X[y_hc == 3,1], s=100, c='cyan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-92d831120f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1532\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "p = model.predict_proba(X_test)\n",
    "p = p[:,1]\n",
    "auc = roc_auc_score(y_test, p)\n",
    "print('AUC: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, p)\n",
    "plot_roc_curve(fpr, tpr)\n",
    "# print(clf.feature_importances_)\n",
    "# importances = clf.feature_importances_\n",
    "# print(f\"Feature Importances{importances}\")\n",
    "# std = np.std(importances, axis=0)\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# for i in indices:\n",
    "#     print(f\"{Xo.columns[i]}\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "# print(f1_score(y_test,p, average='macro'))\n",
    "# print(f1_score(y_test,p, average='micro'))\n",
    "# print(f1_score(y_test,p, average=None))\n",
    "cm = confusion_matrix(y_test, predictions) \n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/allanporter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk.tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def find_ngrams(index):\n",
    "    results = []\n",
    "    #print(len(train_df['post_list'].iloc[index]))\n",
    "    for t in train_df['post_list'].iloc[index]:\n",
    "        t = t.lower()\n",
    "        t = re.sub(r'[^a-zA-Z0-9\\s]', ' ', t)\n",
    "        tokens = [token for token in t.split(\" \") if token != \"\"]\n",
    "        output = list(ngrams(tokens, 3))\n",
    "        results.append(output)\n",
    "    return results\n",
    "ng = [find_ngrams(i) for i in range(len(train_df['post_list']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-34-3ae67364ba45>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-3ae67364ba45>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for n in ng:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from scipy import stats\n",
    "corrs = []\n",
    "for w in range(len(train_df.columns)):\n",
    "    for j in range(len(train_df.columns)):\n",
    "        corrs.append([train_df.columns[w], train_df.columns[j], stats.spearmanr(train_df[train_df.columns[w]], train_df[train_df.columns[j]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "1.  Use lists of words frequencies as the features\n",
    "2.  Try to group together personalities based on features\n",
    "3.  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_hc\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_train, y_train) \n",
    "gnb_predictions = gnb.predict(X_test) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = gnb.score(X_test, y_test) \n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, gnb_predictions) \n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, gnb_predictions, average='macro'))\n",
    "print(f1_score(y_test, gnb_predictions, average='micro'))\n",
    "print(f1_score(y_test, gnb_predictions, average='weighted'))\n",
    "print(f1_score(y_test, gnb_predictions, average=None))\n",
    "probs = gnb_predictions\n",
    "#probs = probs[:,1 \n",
    "# auc = roc_auc_score(y_test, probs)\n",
    "# #print('AUC: %.2f' % auc)\n",
    "\n",
    "p = gnb.predict_proba(X_test)\n",
    "p = p[:,1]\n",
    "auc = roc_auc_score(y_test, p)\n",
    "print('AUC: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, p)\n",
    "plot_roc_curve(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
